{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "seventh-austin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.types import *\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopy.distance\n",
    "import matplotlib\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "from haversine import haversine, Unit\n",
    "\n",
    "import fastplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-tiger",
   "metadata": {},
   "source": [
    "<h2>1-reading initial input data and performing some filters</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-particular",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:==================================================>(9977 + 23) / 10000]22/10/04 08:03:16 WARN nio.NioEventLoop: Selector.select() returned prematurely 512 times in a row; rebuilding Selector io.netty.channel.nio.SelectedSelectionKeySetSelector@43877569.\n",
      "22/10/04 08:03:21 WARN datasources.SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n"
     ]
    }
   ],
   "source": [
    "#schema of initial data \n",
    "schema_initial_data = 'idRequest string, deviceId string, dateTime string, \\\n",
    "latitude double, longitude double, speedKmh Integer, heading Integer,\\\n",
    "accuracyDrop Integer, EngineStatus Integer, Type Integer'\n",
    "#reading csv\n",
    "path = os.path.abspath(os.getcwd())\n",
    "df = spark.read.csv('file:///%s../../shared/data/FCD_complete/*/*'%path,sep=\",\", schema = schema_initial_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accurate-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates\n",
    "df = df.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-support",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "738969717"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/10/04 08:05:05 WARN server.TransportChannelHandler: Exception in connection from /10.42.0.0:45036\n",
      "java.io.IOException: Connection reset by peer\n",
      "\tat sun.nio.ch.FileDispatcherImpl.read0(Native Method)\n",
      "\tat sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)\n",
      "\tat sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)\n",
      "\tat sun.nio.ch.IOUtil.read(IOUtil.java:192)\n",
      "\tat sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)\n",
      "\tat io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)\n",
      "\tat io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)\n",
      "\tat io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)\n",
      "\tat io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)\n",
      "\tat io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n",
      "\tat io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "velvet-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping missing values\n",
    "df = df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping points with accuracy higher than 20\n",
    "df = df.filter(df['accuracyDrop'] <= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "typical-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dateTime format\n",
    "df = df.withColumn('dateTime', F.to_timestamp('dateTime'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "athletic-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-cloud",
   "metadata": {},
   "source": [
    "<strong> Filtering points which are out of our boundary of interest </strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capital-handy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334856698"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============= Torino and countryside ========================================\n",
    "minLat = 44.96282106687191\n",
    "minLon = 7.502048016422193\n",
    "maxLat = 45.19265016665321 \n",
    "maxLon = 7.791812422724604\n",
    "# =============================================================================\n",
    "@F.udf(returnType=BooleanType())\n",
    "def drop_outside_points(lat, lon):\n",
    "    condition = (lat >= minLat) & (lat <= maxLat) & (lon >= minLon) & (lon <= maxLon)\n",
    "    return condition\n",
    "\n",
    "df = df.filter(drop_outside_points('latitude', 'longitude'))\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-subscriber",
   "metadata": {},
   "source": [
    "<h2>2-adding calculated segment parameters to initial data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "proved-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_inital_segment = 'index Integer,idRequest string, deviceId string, dateTime timestamp, \\\n",
    "latitude double, longitude double, speedKmh Integer, heading Integer,\\\n",
    "accuracyDrop Integer, EngineStatus Integer, Type Integer, segmentDistance double,\\\n",
    "segmentDuration double, segmentSpeedKmH double'\n",
    "\n",
    "@F.pandas_udf(schema_inital_segment, functionType=F.PandasUDFType.GROUPED_MAP)\n",
    "def adding_segment_parameter(df):\n",
    "    os.environ[\"ARROW_PRE_0_15_IPC_FORMAT\"] = \"1\"\n",
    "    \n",
    "    df = df.sort_values(by=\"dateTime\")\n",
    "    df.reset_index(inplace=True)\n",
    "    distance=[float(0)]\n",
    "    duration=[float(0)]\n",
    "    speed=[float(0)]\n",
    "    \n",
    "    for index,row in df.iterrows():\n",
    "        if index == len(df)-1:\n",
    "            pass\n",
    "        else:\n",
    "            time_difference = df.loc[index+1,'dateTime'] - df.loc[index,'dateTime']\n",
    "            time_difference = time_difference.total_seconds()\n",
    "            duration.append(time_difference)\n",
    "            \n",
    "            org = (df.loc[index,'latitude'],df.loc[index,'longitude'])\n",
    "            des = (df.loc[index+1,'latitude'],df.loc[index+1,'longitude'])\n",
    "            \n",
    "            distance.append(float(\"{0:.2f}\".format(geopy.distance.distance(org,des).m)))\n",
    "            \n",
    "            try:\n",
    "                speed.append(geopy.distance.distance(org,des).m/time_difference)\n",
    "            except:\n",
    "                speed.append(float(\"NaN\"))\n",
    "        \n",
    "    df['segmentDistance'] = distance\n",
    "    df['segmentDuration'] = duration\n",
    "    df['segmentSpeedKmH'] = [v*3.6 if not pd.isna(v) else float(\"NaN\") for v in speed ]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "capital-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_added_parameters = df.groupby(\"deviceId\").apply(adding_segment_parameter)\n",
    "df_added_parameters = df_added_parameters.drop('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "genetic-andorra",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
